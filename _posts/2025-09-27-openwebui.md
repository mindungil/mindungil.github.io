---
title: open_webui
date: 2025-09-27 17:03:00 +0900
lastmod: 2025-09-28 09:28:00 +0900
categories: [오픈소스, 서비스]
tags: [공부]
author: 길민준
---


## 개요


open_webui는 사용자에게 llm을 제공해주는 웹 프레임워크이다.


전북도청과의 캡스톤 연계로, 도내 직원 대상으로 로컬 LLM을 제공하기 위한 작업을 위해 이전에 수행되었던 open_webui를 이어받아 추가 기능 구현, 안정화, 버전 업데이트 및 최적화를 진행하도록 한다.


## 본문


### 개발 착수


개발에 착수한 지 2주 정도 된 것 같다. 매일은 못 했지만 그래도 프로젝트의 전체적인 틀을 이해하는데 성공했다.


open_webui (프론트-node.js, 백엔드-fastApi, db-sqlite) + VLLM + SGLang + 오픈소스 모델 + etc(STT, RAG) 등으로 이루어져 있다.

이 페이지에서는 open_webui에 대해서 이야기하려고 한다.


### open_webui


자세히는 안 봤지만, open WebUI Team에서 주도하는 오픈소스이다. [https://openwebui.com/](https://openwebui.com/)


커뮤니티가 꽤 방대하고 많은 기여자들이 존재한다. (나도 기여하고싶다.)


보통은 서버에 대규모 모델을 구동시키는 것이 어렵기 때문에 OLllma 의 api를 활용하거나 Claude, Gpt, Gemini 등 api를 이용해서 web 형태로 llm을 이용하는 것 같다.


하지만 우리 프로젝트는 대규모 모델인 DeepSeek R1 이나, OSS 등을 사용한다. 그래서 이 모델들을 안정적으로, GPU를 효율적으로 serving 하기 위해 VLLM, SGLang 같은 백엔드 모델 서빙 프레임워크를 사용한다. VLLM, SGLang에 대해서는 다음에 포스팅하는 것으로 한다.


우리가 프로젝트를 배포하는 방식은 각 기능 당 컨테이너를 띄우고 컨테이너 간 통신하는 방법을 채택한다.


현재 안정화된 컨테이너들은 크게 open_webui, vllm, sglang 이렇게 있다.


컨테이를 활용하면 정말 다 되어있는 틀을 제공받는 것이라, 컨테이너 실행 명령어로 세부 사항들을 조정하며 모델을 안정적으로 띄울 수 있다.


**프론트**:


    버전:


        현재 v0.6.31 추진 중


        v0.6.30 테스트 후 커스텀 로직 반영 후 안정화 성공


        가상 DOM을 만들지 않는, svelte를 프론트 언어로 사용한다.


    기능:


        LLM 인터페이스, 왼쪽의 사용자 라이브러리(대화 검색, 노트, 워크스페이스, 대화내역), 모델 파라미터 세부 조정, 설정, 관리자 페이지(사용자 관리, 모델 평가, function, 설정 등) 이 있다.


        Function:


            – OpenWebUI 내부에서 직접 실행되는 기능 확장 방식


            – 모델 응답 과정 중에 호출되는 기능 (예: 함수 호출, 툴 연동)


            – 간단한 로직을 추가하거나 모델 내 기능을 확장할 때 적합


        Pipeline:


            – 별도의 서버(또는 컨테이너)로 실행되는 확장 가능한 워크플로우


            – OpenWebUI 인스턴스의 부하를 줄이면서 복잡한 처리나 외부 라이브러리 사용 가능


            – 모델 호출 전/후 흐름을 가로채거나, 별도의 “Pipe” 모델처럼 동작 가능


            – Functions보다 설정이 복잡하지만 유연성이 큼


    **백엔드:**


        구조:


            여러 스크립트가 있지만 중요한 것은,


            내부 DB:


                open-webui/backend/data


                이 디렉토리에 내부 정보가 담겨있다. 용량이 크고 배포할 때 주의해야 한다.


